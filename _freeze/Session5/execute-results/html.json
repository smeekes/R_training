{
  "hash": "3c425f69d638df6fbc15daeb96873c9a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Introduction to R\"\nsubtitle: \"Session 5\"\nauthor: \"\"\nfilters:\n  - diagram\ndiagram:\n  engine:\n    tikz:\n      header-includes:\n        - '\\usepackage{adjustbox,xcolor}'\n        - '\\usetikzlibrary{arrows, shapes}'\n        - '\\definecolor{UMdblue}{RGB}{0,28,61}'\n        - '\\definecolor{UMlblue}{RGB}{0,162,219}'\n        - '\\definecolor{UMorangered}{RGB}{232,78,16}'\n        - '\\definecolor{UMorange}{RGB}{243,148,37}'\n        - '\\definecolor{UMred}{RGB}{174,11,18}'\n---\n\n\n\n# Session Overview\n\n1.  [Basics of Data Manipulation](#dataman1)\n2.  [Regression Analysis](#reg1)\n3.\t[Bonus: Tidyverse](#dataman2)\n\n# Basics of Data Manipulation {#dataman1}\n\n## Data Manipulation\nIn the last session, we learned how to load data of various sources into R. \n\nToday's first part will be about how to manipulate data in R. Importantly, we will learn how to\n\n- select certain variables from a data \n- subset a data set\n- recode and rename certain variables\n\nWe will work with fictive data set of student grades. Let us start by loading the data:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_grades <- read.table(\"data/grades.csv\", \n                       header = TRUE, sep = \",\", stringsAsFactors = FALSE)\n```\n:::\n\n\n\n## Selecting Variables\nWe begin with selecting interesting variables from a data set. For our grades data set, we want to preserve information about `ID`, `Name`, and `Exam_Score`, and drop all other information. \n\nVariables can be selected by name, after which we inspect the first and last three rows in the data set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data_grades[, c(\"ID\", \"Name\", \"Exam_Score\")] \nhead(data, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      ID                Name Exam_Score\n1 i40333 Hyden-Terry, Dakota         55\n2 i41204     Polson, Destiny         82\n3 i41428       al-Azad, Nuha         52\n```\n\n\n:::\n\n```{.r .cell-code}\ntail(data, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        ID             Name Exam_Score\n40 i198051      Nies, Tyler         62\n41 i198310 Montano, Marquez         72\n42 i198859  Nyberg, Bich Sa         91\n```\n\n\n:::\n:::\n\n\n\n## Selecting Variables\nOr by variable indexes\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata1 <- data_grades[, c(1, 2, 7)] \n```\n:::\n\n\nthough this is not that convenient unless you know the column numbers of the variables you want to select.\n\nA more convenient alternative is to use the following function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata2 <- subset(data_grades, select = c(ID, Name, Exam_Score))\n```\n:::\n\n\n\nThe objects data, data1 and data2 are all identical so you can use your preferred way of working!\n\n## Subsetting Rows\nNext, we want to subset the data set, i.e. preserve interesting rows while removing the others. \n\nFor the grades data set, we might be interested in information about students in tutorial group 1: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# select tutorial 1 students only\ndata_tutorial1 <- data_grades[data_grades$Tutorial == 1, ]\n```\n:::\n\n\nor alternatively:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_tutorial1 <- subset(data_grades, Tutorial == 1)\n```\n:::\n\n\n\nSubsetting also works using characters. For instance, to retrieve only information for females:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# select female students only\ndata_females <- data_grades[data_grades$Gender == 'Female', ]\n```\n:::\n\n\n\nInspect your new data sets!\n\n## Exercise 5.1\n\nUse the grades data set.\n\n1. Generate a data set that contains information about the student ID, student name,  their tutorial group, participation grade and their exam score.\n\n2. Reduce the data set to only display information of students in tutorial group 4\n\n3. Further reduce the data set to only display information of students in tutorial group 4 with an exam score of more than 80. How many such students are there? \nHint: You can use a logical operator when subsetting!\n\n## Transforming Variables \nLet us continue with further data manipulations. The variable tutorial is currently an integer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(data_grades$Tutorial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"integer\"\n```\n\n\n:::\n:::\n\n\nbut it should be a factor (a categorical variable). This can be easily changed in R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_grades$Tutorial <- as.factor(data_grades$Tutorial)\n```\n:::\n\n\nafter which you can inspect its new class:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(data_grades$Tutorial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"factor\"\n```\n\n\n:::\n:::\n\n\n\n## Transforming Variables \nWhen inspecting the variable itself, R now mentions the different levels of the factors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_grades$Tutorial\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 2 3 4 2 1 4 3 1 1 3 4 2 4 4 3 1 3 4 1 2 1 1 3 1 3 3 2 3 2 1 4 4 4 2 3 2 2 4\n[39] 4 2 1 3\nLevels: 1 2 3 4\n```\n\n\n:::\n:::\n\n\nwhich you can also directly retreive via:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(data_grades$Tutorial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"1\" \"2\" \"3\" \"4\"\n```\n\n\n:::\n:::\n\n\n\n## Adding Variables\nSometimes we want to add a variable to an existing data set. \n\nFor instance, we want to add the exam score on 10 instead of 100. To add a new variable, use the `$` operator and specify a new variable name:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_grades$Exam_Score_10 <- data_grades$Exam_Score/10 \n\nhead(data_grades[, c(\"Exam_Score\", \"Exam_Score_10\")], 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Exam_Score Exam_Score_10\n1         55           5.5\n2         82           8.2\n3         52           5.2\n```\n\n\n:::\n:::\n\n\n\n## Exercise 5.2\n\n1. What is the class of the variable Tutor? Transform it into a factor. How many tutors are there?\n\n2. Add a new variable to compute the final score of each student, which is the weighted average of their participation grade (20%) and their exam score (80%)\n\n3. Retrieve the final score of the students in tutorial group 2. Obtain summary statistics of their final scores.\n\n4. What is the lowest and the highest score in tutorial group 2? Retrieve this information from the summary statistics as well as by using a dedicated function.\n\n# Regression Analysis {#reg1}\n\n## General Information\n\nIn what follows, we consider the **linear regression model**\n\n$$y_i = \\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\dots + \\beta_p x_{p,i} + u_i,\\ i=1,\\dots,n.$$\n \n\nWe will first estimate the following simple regression for the grades data set:\n$$Final\\_Score = \\beta_0 + \\beta_1 Exam\\_Score + u,$$\n\nassuming the `Final_Score` variable was added to the grades data set in Exercise 5.2:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_grades$Final_Score <- 0.2*data_grades$Participation_Grade + 0.08*data_grades$Exam_Score\n```\n:::\n\n\n\n## Formula Objects and the lm Function\n\nR is designed to easily estimate various statistical models. It provides a specific object class to symbolically describe statistical models, called `formula` objects. See `?formula` for more details.\n\nOur regression model \n\n$$Final\\_Score = \\beta_0 + \\beta_1 Exam\\_Score + u$$\n\ncan be specified in R as a `formula` like this: \n\n`Final_Score ~ Exam_Score`\n\nwhere \n`~` is the basis for all models:  `y ~ model` specifies that the dependent variable `y` is modeled using the linear predictors described in `model`.\n\nThe standard function for estimating linear models is `lm()`. Estimating a regression model in R then only requires one line of code!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# example simple regression:\nreg_1 <- lm(Final_Score ~ Exam_Score, data = data_grades)\n```\n:::\n\n\n\n## Summary of lm\nLet us now inspect the summary output of our estimated regression model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# regression summary output:\nsummary(reg_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Final_Score ~ Exam_Score, data = data_grades)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30309 -0.11303  0.02373  0.08376  0.36362 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.415785   0.102380   4.061 0.000221 ***\nExam_Score  0.093342   0.001513  61.702  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1577 on 40 degrees of freedom\nMultiple R-squared:  0.9896,\tAdjusted R-squared:  0.9893 \nF-statistic:  3807 on 1 and 40 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n## From Simple to Multiple Regression\nGoing from a simple to a multiple regression model is easy. For example, let us add the variable `GPA` as a second predictor this can easily be done by adjusting the `formula` to:\n\n`Final_Score ~ Exam_Score + GPA`\n\nwhere `+` now separates the different predictors included in the model. \n\nEstimating the multiple regression model in R can be done as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# example multiple regression:\nreg_2 <- lm(Final_Score ~ Exam_Score + GPA, data = data_grades)\n```\n:::\n\n\n\n## Summary of lm\nThe summary output of our newly estimated regression model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# regression summary output:\nsummary(reg_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Final_Score ~ Exam_Score + GPA, data = data_grades)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.29747 -0.09831  0.04013  0.08448  0.33083 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.355004   0.125876   2.820  0.00751 ** \nExam_Score  0.091791   0.002397  38.298  < 2e-16 ***\nGPA         0.024400   0.029179   0.836  0.40814    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1583 on 39 degrees of freedom\nMultiple R-squared:  0.9898,\tAdjusted R-squared:  0.9893 \nF-statistic:  1890 on 2 and 39 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n## lm and Variable Transformations\nImagine you want to estimate a regression model on log-transformed variables, for example:\n$$log(Final\\_Score) = \\beta_0 + \\beta_1 log(Exam\\_Score) + u$$\nThis can be done by directly using the `log` function in the `lm` function: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# example log-transformed variables\nreg_3 <- lm(log(Final_Score) ~ log(Exam_Score), data = data_grades)\n```\n:::\n\n\n\n## lm and Variable Transformations\nWhat if you want to include square of a predictor? For example:\n$$Final\\_Score = \\beta_0 + \\beta_1 Exam\\_Score  + \\beta_2 Exam\\_Score^2 + u$$\nYou CANNOT use  `Final_Score ~ Exam_Score + Exam_Score^2` since the `^2` has a special (different) meaning in a formula object. \n\nInstead, you should use the function `I()`. More specifically:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# example squared variables\nreg_4 <- lm(Final_Score ~ Exam_Score + I(Exam_Score^2), data = data_grades)\n```\n:::\n\n\ndoes the job! Inspect its summary output.\n\n## lm and Variable Transformations\nLet us now add a dummy variable to the estimated regression model:\n$$Final\\_Score = \\beta_0 + \\beta_1 Exam\\_Score  + \\beta_2 Male + u$$\nwhere `Male` is a dummy variable that takes on the value 1 for male students, and 0 otherwise.\n\n\nLet us start by transforming the variable `Gender` to a factor:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_grades$Gender <- as.factor(data_grades$Gender)\n```\n:::\n\n\nFactor variables in formulas are then automatically *dummy coded*. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# example dummy variables\nreg_5 <- lm(Final_Score ~ Exam_Score + Gender, data = data_grades)\n```\n:::\n\n\n\n## Summary of lm\nInspect the summary output of the regression model with a continuous predictor and a dummy variable; you will notice that R has estimated the regression model with female students as the baseline: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# example dummy variables\nsummary(reg_5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Final_Score ~ Exam_Score + Gender, data = data_grades)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.29877 -0.11731  0.02362  0.08789  0.36792 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.420303   0.106849   3.934 0.000334 ***\nExam_Score   0.093338   0.001532  60.942  < 2e-16 ***\nGenderMale  -0.008569   0.049262  -0.174 0.862801    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1596 on 39 degrees of freedom\nMultiple R-squared:  0.9896,\tAdjusted R-squared:  0.9891 \nF-statistic:  1857 on 2 and 39 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n## lm and Variable Transformations\nFinally, let us investigate how interaction terms can be included in a regression model. We consider the model:\n$$Final\\_Score = \\beta_0 + \\beta_1 Exam\\_Score  + \\beta_2 Male  + \\beta_3 Male\\cdot Exam\\_Score + u$$\nThe regression can be estimated in R via the command:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# example dummy variables\nreg_6 <- lm(Final_Score ~ Exam_Score + Gender + Exam_Score:Gender , data = data_grades)\n```\n:::\n\n\nwhere `:` creates interaction terms between variables.\n\nOr in short:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# example dummy variables\nreg_7 <- lm(Final_Score ~ Exam_Score*Gender, data = data_grades)\n```\n:::\n\n\ndoes the same since `a*b` in the  `Formula` object is equivalent to `a + b + a:b` \n\n\n## Summary of lm\nInspect the summary output of the estimated regression model with interaction terms:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# example dummy variables\nsummary(reg_6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Final_Score ~ Exam_Score + Gender + Exam_Score:Gender, \n    data = data_grades)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30170 -0.11724  0.01739  0.08461  0.36672 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            0.4574339  0.1694149   2.700   0.0103 *  \nExam_Score             0.0927754  0.0025125  36.925   <2e-16 ***\nGenderMale            -0.0683631  0.2158588  -0.317   0.7532    \nExam_Score:GenderMale  0.0009089  0.0031924   0.285   0.7774    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1615 on 38 degrees of freedom\nMultiple R-squared:  0.9896,\tAdjusted R-squared:  0.9888 \nF-statistic:  1209 on 3 and 38 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n## Exercise 5.3\n\n1. Estimate the following simple regression model in R: \n$$Final\\_Score = \\beta_0 + \\beta_1 Participation\\_Grade + u$$\nIs the variable `Participation_Grade` significant? What is the value of the R^2?\n\n3. Estimate the multiple regression model: \n$$Final\\_Score = \\beta_0 + \\beta_1 Participation\\_Grade +\n\\beta_2 Chang + u$$\nwhere `Chang` is a dummy variable taking the value 1 for students having tutor \"Chang, Stevens\" and 0 otherwise. Is the dummy variable  significant?\n\n4. Imagine you want to include the tutor \"Chang, Stevens\" as the baseline level. \nRe-estimate the regression model after you have re-specified your factor variable `Tutor` thereby explicitly defining  \"Chang, Stevens\"  as the baseline level. Hint: use the function `relevel` to this end.\n\n5. Finally, estimate the regression model:\n$$Final\\_Score = \\beta_0 + \\beta_1 Participation\\_Grade +\n\\beta_2 Chang + \\beta_3 Participation\\_Grade \\cdot Chang + u$$\nand inspect the summary output.\n\n\n## Accessing Regression Results\nFinally, we  discuss how important output of a regression analysis can be directly accessed in R. \n\nFirst, assume you want to access the estimated coefficients of an estimated regression model. This can done using the function `coefficients()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# accessing coefficients:\nreg_2 <- lm(Final_Score ~ Exam_Score + GPA, data = data_grades)\ncoefficients(reg_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)  Exam_Score         GPA \n 0.35500372  0.09179130  0.02439952 \n```\n\n\n:::\n:::\n\n\n\nAlternatively, you can directly access the coefficients in the list of the `lm` object `reg_2` :\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# accessing coefficients:\nreg_2$coefficients \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)  Exam_Score         GPA \n 0.35500372  0.09179130  0.02439952 \n```\n\n\n:::\n:::\n\n\n\nNote that you can do the same for accessing the fitted values (function `fitted()` or slot `$fitted.values`) or the residuals (function `residuals()`  or slot `$residuals`) of your estimated regression model.\n\n## Accessing Regression Results\nWhat if you want to access the $R^2$, or the $t$-stats and $p$-values. Unfortantely, the list object `reg_2`  does not seem to contain this information:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# information stored in lm-object\nnames(reg_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n```\n\n\n:::\n:::\n\n\n\nThis does not mean that you cannot access it. Instead this information can be accessed via the slots in the list object of `summary(reg_2)`! \n\n## Accessing Regression Results\nIn particular: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# summary object contains additional information:\nsum_reg_2 <- summary(reg_2)\nsum_reg_2$coefficients      ## matrix with estimates, standard errors, t-stat, p-value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              Estimate  Std. Error    t value     Pr(>|t|)\n(Intercept) 0.35500372 0.125875805  2.8202697 7.505466e-03\nExam_Score  0.09179130 0.002396776 38.2978227 1.474928e-32\nGPA         0.02439952 0.029179248  0.8361943 4.081399e-01\n```\n\n\n:::\n\n```{.r .cell-code}\nsum_reg_2$sigma             ## residual standard error estimate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.158261\n```\n\n\n:::\n\n```{.r .cell-code}\nsum_reg_2$r.squared         ## R^2 of regression\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9897858\n```\n\n\n:::\n\n```{.r .cell-code}\nsum_reg_2$adj.r.squared     ## adjusted R^2 of regression\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.989262\n```\n\n\n:::\n:::\n\n\n\n## Task 5.4\nEstimate the regression model\n$$Exam\\_Score = \\beta_0 + \\beta_1 Participation\\_Grade + \\beta_2 Male + \\beta_3 Male \\cdot Participation\\_Grade    + u$$\n\n1.  Is the dummy `Male` significant?\n\n2.  What are the values of the $t$-stats for the 3 predictors? Retrieve this information from the summary output but also saved their values in a new variable called `my_tstats`. Note: save ONLY the values of the t-stats!\n\n3.  What is the estimated coefficient, standard error, $t-$value and $p-$value of the predictor $Participation\\_Grade$? Save this (and ONLY this) information in new variable called `my_grade_info` and display the information thereby rounding to two digits.\n\n4. What is the value of the adjusted $R^2$ ? Retrieve this information from the summary output but also saved its value in a new variable called `my_adjR2`.\n\n5. Store the residuals in a new variable called `my_resid`. Make a scatter plot of the residuals, thereby labeling the x-axis as 'Student index', the y-axis as 'Residuals' and displaying the dots in red.\n\n6. Store the fitted values in a new variable called `my_fitted`. Make a scatter plot of the actual exam scores on the x-axis and the fitted values on the y-axis. Label the x-axis as 'Exam scores', the y-axis as 'Fitted values', and give the plot the title 'Fitted versus Actual'.\n\n# Bonus: Tidyverse {#dataman2}\n\n## Consistent Work with Data: tidyverse\n\nNext, we will (superficially) cover the package [dplyr](https://dplyr.tidyverse.org/). This package is part of the [tidyverse](https://www.tidyverse.org/), a collection of R packages designed to provide a consistent approach to working with data. The following packages belong to the [tidyverse](https://www.tidyverse.org/):\n\n - [dplyr](https://dplyr.tidyverse.org/): \"Grammar of Data Manipulation\"\n\n - [ggplot2](https://ggplot2.tidyverse.org/): \"Grammar of Graphics\"\n\n - [readr](https://readr.tidyverse.org/): \"Fast and friendly way to read rectangular data\"\n\n - [tibble](https://tibble.tidyverse.org/): \"A tibble, or tbl_df, is a modern reimagining of the data.frame\"\n\n - [tidyr](https://tidyr.tidyverse.org/): \"Create tidy data. Tidy data is data where:\n      1. Every column is a variable.\n      2. Every row is an observation.\n      3. Every cell is a single value.\"\n\n - [purrr](https://purrr.tidyverse.org/): \"Enhance R’s functional programming toolkit\"\n\nNote: The philosophy (and syntax) of [tidyverse](https://www.tidyverse.org/) differs completely from base-R and is somewhat similar to Python's `pandas`. Some argue tidyverse code is more readable and intuitive, others find it rather unhandy. R code written by AI models typically utilizes packages from the tidyverse.\n\n\n## Pipes\nAn important component of working with data and `dplyr` is the pipe operator `%>%`, included in the `magrittr` package. The goal of this operator (also found in many other languages) is to make function composition more readable in code.\n\nExample:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\nf <- function(x) x + 10\ng <- function(x) x * 2\n\na <- 2\nf(g(a))         # 2*a + 10 -> 14\n\n## Same result using the pipe operator\na %>% g() %>% f()\n```\n:::\n\n\n\n## Pipes\nYou can use **dplyr** with `%>%` to select variables, or subset rows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select Student ID, Name and Exam_Score\ndata_grades %>% dplyr::select(ID, Name, Exam_Score)\n\n# Select Exam_Score from data set and display its summary\ndata_grades %>% dplyr::select(Exam_Score) %>% summary()\n\n# Subset on students belonging to tutorial group 1\ndata_grades %>% dplyr::filter(Tutorial==1)\n\n# Subset on female students \ndata_grades %>% dplyr::filter(Gender=='Female') \n\n# Adding variables\ndata_grades <- data_grades %>% mutate(Exam_Score_10 = Exam_Score/10)\n```\n:::\n\n\n\n## `dplyr`\n\nSome key functions of `dplyr` are:\n\n- [`mutate()`](https://dplyr.tidyverse.org/reference/mutate.html): Add new variables to a dataset\n\n- [`select()`](https://dplyr.tidyverse.org/reference/select.html): Select variables (columns)\n\n- [`filter()`](https://dplyr.tidyverse.org/reference/filter.html): Select observations (rows)\n\nYou can revisit some of the earlier exercises and now try to execute them using `dplyr`!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}